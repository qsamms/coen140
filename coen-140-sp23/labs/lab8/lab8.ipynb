{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CndVY51ENbZi"
      },
      "source": [
        "# K Nearest Neighbour Search \n",
        "\n",
        "A k-nearest neighbor (kNN) search finds the k nearest vectors to a query vector, as measured by a similarity metric. \n",
        "\n",
        "We will use the kNN algorithm to find some nearest neighbors and then compute the recall of the neighborhood we found. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev7Y79FYJS1P",
        "outputId": "bd214285-1555-4135-b725-197313ad1b58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/david/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import libraries\n",
        "import numpy as np  \n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bA_aH-lSCQl"
      },
      "source": [
        "We will be using Amazon Reviews Dataset. This dataset consists of a few million Amazon customer reviews (input text) and star ratings (output labels). Additional information found here: https://s3.amazonaws.com/amazon-reviews-pds/readme.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "eFztkx7E14Lt"
      },
      "outputs": [],
      "source": [
        "# Read the dataset\n",
        "data = pd.read_csv('Reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp1DHNsu3J-h",
        "outputId": "ce0f0737-ab17-4bcf-8e42-ef0210911182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20000, 10)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print out the shape of the dataframe\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qpXur067l2q2",
        "outputId": "29839a59-2f90-48ed-bb7e-17e079ee6186"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>ADT0SRK1MGOEU</td>\n",
              "      <td>Twoapennything</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1342051200</td>\n",
              "      <td>Nice Taffy</td>\n",
              "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1SP2KVKFXXRU1</td>\n",
              "      <td>David C. Sullivan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1340150400</td>\n",
              "      <td>Great!  Just as good as the expensive brands!</td>\n",
              "      <td>This saltwater taffy had great flavors and was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A3JRGQVEQN31IQ</td>\n",
              "      <td>Pamela G. Williams</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1336003200</td>\n",
              "      <td>Wonderful, tasty taffy</td>\n",
              "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>B000E7L2R4</td>\n",
              "      <td>A1MZYO9TZK0BBI</td>\n",
              "      <td>R. James</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1322006400</td>\n",
              "      <td>Yay Barley</td>\n",
              "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>B00171APVA</td>\n",
              "      <td>A21BT40VZCCYT4</td>\n",
              "      <td>Carol A. Reed</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1351209600</td>\n",
              "      <td>Healthy Dog Food</td>\n",
              "      <td>This is a very healthy dog food. Good for thei...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
              "6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
              "7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
              "8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
              "9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "5                     0                       0      4  1342051200   \n",
              "6                     0                       0      5  1340150400   \n",
              "7                     0                       0      5  1336003200   \n",
              "8                     1                       1      5  1322006400   \n",
              "9                     0                       0      5  1351209600   \n",
              "\n",
              "                                         Summary  \\\n",
              "0                          Good Quality Dog Food   \n",
              "1                              Not as Advertised   \n",
              "2                          \"Delight\" says it all   \n",
              "3                                 Cough Medicine   \n",
              "4                                    Great taffy   \n",
              "5                                     Nice Taffy   \n",
              "6  Great!  Just as good as the expensive brands!   \n",
              "7                         Wonderful, tasty taffy   \n",
              "8                                     Yay Barley   \n",
              "9                               Healthy Dog Food   \n",
              "\n",
              "                                                Text  \n",
              "0  I have bought several of the Vitality canned d...  \n",
              "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  This is a confection that has been around a fe...  \n",
              "3  If you are looking for the secret ingredient i...  \n",
              "4  Great taffy at a great price.  There was a wid...  \n",
              "5  I got a wild hair for taffy and ordered this f...  \n",
              "6  This saltwater taffy had great flavors and was...  \n",
              "7  This taffy is so good.  It is very soft and ch...  \n",
              "8  Right now I'm mostly just sprouting this so my...  \n",
              "9  This is a very healthy dog food. Good for thei...  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvinrJ45QZO0"
      },
      "source": [
        "Text preprocessing \n",
        "\n",
        "We will be removing stop-words, any punctuations or limited set of special characters like , or . or # etc. Then, we go on to snowball stemming the word and convert it to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "vJLdTUv0qs64"
      },
      "outputs": [],
      "source": [
        "# Set of stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "# Initialising the snowball stemmer\n",
        "sno = nltk.stem.SnowballStemmer('english') \n",
        "\n",
        "# Function to clean the word of any html-tags\n",
        "def cleanhtml(sentence): \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', sentence)\n",
        "    return cleantext\n",
        "\n",
        "# Function to clean the word of any punctuation or special characters\n",
        "def cleanpunc(sentence): \n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return  cleaned\n",
        "\n",
        "i=0\n",
        "str1=' '\n",
        "final_string=[]\n",
        "\n",
        "# Store words from +ve reviews \n",
        "all_positive_words=[]\n",
        "\n",
        "# Store words from -ve reviews\n",
        "all_negative_words=[] \n",
        "s=''\n",
        "\n",
        "final_string=[]\n",
        "all_positive_words=[] \n",
        "all_negative_words=[] \n",
        "s=''\n",
        "for sent in data['Text'].values:\n",
        "    filtered_sentence=[]\n",
        "\n",
        "    # Remove HTMl tags\n",
        "    sent=cleanhtml(sent) \n",
        "    for w in sent.split():\n",
        "        for cleaned_words in cleanpunc(w).split():\n",
        "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
        "                if(cleaned_words.lower() not in stop):\n",
        "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
        "                    filtered_sentence.append(s)\n",
        "                else:\n",
        "                    continue\n",
        "            else:\n",
        "                continue \n",
        "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words    \n",
        "    final_string.append(str1)\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAa6zXeVRAYA"
      },
      "source": [
        "Generate bag of words vector matrix for reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZfLc1SSix7x3"
      },
      "outputs": [],
      "source": [
        "count_vect = CountVectorizer() \n",
        "final_bow_count = count_vect.fit_transform(final_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "H5o7zLU13bEv"
      },
      "outputs": [],
      "source": [
        "final_bow_np = StandardScaler(with_mean=False).fit_transform(final_bow_count )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8eTAhjNRJvS"
      },
      "source": [
        "Split the data into Train and Test into a 9:1 split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ytcJIeZW3yDC"
      },
      "outputs": [],
      "source": [
        "X = final_bow_np\n",
        "\n",
        "X_train =  final_bow_np[:math.ceil(len(data)*.9)] \n",
        "X_test = final_bow_np[math.ceil(len(data)*.9):]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the 50 nearest neighbors for each sample in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "sr02yfD-lNsd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.23 s, sys: 760 ms, total: 1.99 s\n",
            "Wall time: 2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "k = 50\n",
        "nbrs = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='cosine').fit(X_train)\n",
        "distances, neighbors = nbrs.kneighbors(X_test, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2waknjX0HPh",
        "outputId": "911ac5d9-5c7f-42e0-eef5-e7d734f5ab93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[6.18464162e-01, 7.16116166e-01, 7.55184269e-01, ...,\n",
              "        9.39110042e-01, 9.39593503e-01, 9.39595312e-01],\n",
              "       [6.84371145e-01, 7.00441545e-01, 7.02512885e-01, ...,\n",
              "        8.69142303e-01, 8.70446927e-01, 8.70674543e-01],\n",
              "       [5.34895648e-01, 6.37843018e-01, 6.56247624e-01, ...,\n",
              "        9.12725473e-01, 9.13171758e-01, 9.13337868e-01],\n",
              "       ...,\n",
              "       [0.00000000e+00, 6.27357430e-01, 6.80607607e-01, ...,\n",
              "        9.17175649e-01, 9.18609906e-01, 9.18658569e-01],\n",
              "       [0.00000000e+00, 4.72554556e-01, 6.08074531e-01, ...,\n",
              "        9.28125513e-01, 9.28183424e-01, 9.28417540e-01],\n",
              "       [2.22044605e-16, 5.65968666e-01, 5.89778151e-01, ...,\n",
              "        8.88874262e-01, 8.88950398e-01, 8.89400426e-01]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Ae_dJfIH0I",
        "outputId": "256b95ee-d82c-4312-8f94-012df803d38c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[12186, 13757, 13091, ..., 13728, 12408,  7513],\n",
              "       [ 9565,  7384, 10521, ...,  9948, 12740, 10799],\n",
              "       [17992, 17338, 17998, ..., 15123,   352,   807],\n",
              "       ...,\n",
              "       [11088, 12352, 11107, ...,  1771,  4423,  3060],\n",
              "       [11089, 17989,  7498, ...,  9398,  7994,  1629],\n",
              "       [11090, 11543, 11687, ...,  1527, 15503,  7154]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neighbors"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the average recall of the found neighbors. For each sample, the recall is computed as the number of found neighbors divided by the number of neighbors to be found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Z8W3eb7KL9Pz"
      },
      "outputs": [],
      "source": [
        "def recall(pred, gt):\n",
        "    \"\"\"Compute the recall of the pred neighborhood vs. the gt neighborhood\"\"\"\n",
        "    if pred.shape[0] == 1:\n",
        "        return len(set(pred).intersection(set(gt)))/len(gt)\n",
        "    assert pred.shape[0] == gt.shape[0]\n",
        "    return np.array([len(set(pred[i]).intersection(set(gt[i])))/len(gt[i]) for i in range(len(pred))]).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0028399999999999996"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recall for a random assignment of neighbors\n",
        "recall(np.random.randint(len(neighbors), size=(len(neighbors), k)), neighbors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9399999999999995"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recall if the last 3 neighbors were missed for each sample\n",
        "recall(neighbors[:, range(k-3)], neighbors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss-me5avMKqf",
        "outputId": "977a5e13-5f7a-4b95-933d-e7ee27ca6f73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recall if you found all the correct neighbors\n",
        "recall(neighbors, neighbors)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mz8QtMWbEOC"
      },
      "source": [
        "# References\n",
        "\n",
        "1. https://scikit-learn.org/stable/modules/neighbors.html\n",
        "3. https://medium.com/analytics-vidhya/k-nearest-neighbor-algorithm-with-amazon-food-reviews-analysis-14d83a4cadea \n",
        "4. https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kEtAwM8KS27Z"
      },
      "source": [
        "# Task\n",
        "\n",
        "1. Execute Approximate Nearest Neighbor search using TWO of the tools of your choice from the ANN benchmarks. https://ann-benchmarks.com/. Please visit http://github.com/erikbern/ann-benchmarks/ to get an overview of evaluated algorithms and their performance.\n",
        "\n",
        "2. Train your ANN models for k=50 using the Train-Test split above and tune their parameters to achieve a recall of at least 80%.\n",
        "\n",
        "3. For each method, display the recall as well as the overall time (training and search) for the search process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
